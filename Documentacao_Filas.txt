Todos tem que receber as filas que consomem e que inserem
Todos precisam de adicionar um None ao final da fila

def spider(url, ignorecache, ToProcessUrlQueue):   
recebe uma lista de urls, boolean ignorecache e a fila de urls a serem processadas, onde ele insere as urls

def getLinks(self, url): #producer 
async def getLinks(self, ToProcessUrlQueue, ToConsumeDataQueue, ToConsumeUrlQueue, ToStoreDataQueue, ToStoreUrlQueue): #producer 
recebe a lista de urls a serem processadas (ToProcessUrlQueue)
insere os dados a serem consumidos nas filas ToConsumeDataQueue, que vai pra função ConsumeHtml e ToStoreDataQueue que vai pra função storeCache.
Insere também as urls correspondentes aos dados nas filas ToConsumeUrlQueue (consumida na ConsumeHtml) e ToStoreUrlQueue (consumida na storeCache)


async def storeCache(ToStoreDataQueue, ToStoreUrlQueue):
recebe a fila com os conteúdos html onde serão guardados em cache (ToStoreDataQueue) e a lista com as respectivas urls (ToStoreUrlQueue).

async def ConsumeHtml (word, ToConsumeDataQueue, ToConsumeUrlQueue, FinalQueue):
recebe o termo que vai ser buscado, a fila com os conteúdos html onde serão buscados os termos (ToConsumeDataQueue) e a lista com as respectivas urls (ToConsumeUrlQueue).
insere a quantidade de ocorrências e as urls em que foram encontrados os termos na FinalQueue

async def createreturn(FinalQueue):
recebe a fila com a quantidade de ocorrências e as urls em que foram encontrados os termos, monta o objeto e retorna para ser apresentado como Json.

def removeCache(url):
removida pra facilitar o gerenciamento de filas

def formatanomearquivowindows(url): 
#Removida pra facilitar o gerenciamento de filas


